{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# import os\n",
    "\n",
    "# from dotenv import load_d otenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A16z continues to deposit MKR to Coinbase via address 0x127941a7741bf11b0391fe995beb60852e5ec13f. 1 hour ago, address 0x127941a transferred 1.38K MKR (~$1.5M) at a price of $1.11K. In the past, A16z transferred 6.9K MKR (~$7M) to address 0x127941 on 20-21/7/2023. The average price was $1.017K. This address also recently transferred a similar amount of MKR to Coinbase yesterday. A16z address: 0x05e793ce0c6027323ac150f6d45c2344d28b6019.\"\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "- A16z ti·∫øp t·ª•c  deposited MKR to Coinbase via address 0x127941a7741bf11b0391fe995beb60852e5ec13f\n",
    "- 1h tr∆∞·ªõc, address 0x127941a ƒë√£ chuy·ªÉn 1.38K MKR (~$1.5M) at price $1.11K\n",
    "Trong qu√° kh·ª©: \n",
    "- A16z: chuy·ªÉn 6.9K MKR (~$7M) cho address 0x127941 v√†o 20-21/7/2023.\n",
    "- AVG price: $1.017K. \n",
    "- Address n√†y c≈©ng v·ª´a  chuy·ªÉn 1 l∆∞·ª£ng MKR t∆∞∆°ng t·ª± h√¥m n√†y cho coinbase v√†o h√¥m qua.\n",
    "Address A16z: 0x05e793ce0c6027323ac150f6d45c2344d28b6019\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "t√¥i c√≥ c√°c d·ªØ li·ªáu sau, h√£y vi·∫øt th√†nh 1 tweet b·∫±ng ti·∫øng anh:\n",
    "{text}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "1. Who made the transaction? -> Hashkey\n",
    "2. How long is the trading period? -> 14 hours ago\n",
    "3. What action is it? Moved out $ETH\n",
    "4. Total amount of token(s) traded? 4556 $ETH\n",
    "5. From/to where? To Binance\n",
    "6. Average price? Total value of the transaction? (in USD)? $1,899 and $8.65M, respectively\n",
    "7. Any interesting detail(s) about the transaction period? during $ETH price surge\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "8. How much was the previous PnL? Estimated realized profit by trading $ETH before this trade was $1.7M+ \n",
    "9. How many trading cycles have been done? The information is unknown\n",
    "10. From which source did the trader get the tokens? Accumulated 18,244 $ETH from Binance\n",
    "11. What was previous average buying/selling price?  Total value of the transaction (in USD)? Got $ETH at $1,670 and $30.47M, respectively\n",
    "12. How was the previous trading patterns? Hashkey has smartly caught 2 largest dumps ($USDC depeg in Mar and $USDT depeg in Jun). They also cleared $ETH at $2.1K ~ the peak of the year on Apr 18.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Can you help generate a twitter thread with the following info:\n",
    "{text1}\n",
    "Building on the 7 questions above create a more concise tweet thread to answer those 7 questions using the information I've given you with a few emojis and more action verbs.\n",
    "\n",
    "In particular, emphasize \"estimated to realize $1.04M (ROI: 13.17%) from this trade\" in the paragraph about Hashkey moving $ETH out to Binance.\n",
    "\n",
    "Avoid repeating the same information and don't add 1/7 üíº at the beginning of each sentence. Keep it simple and avoid additional subjective statements.\n",
    "\n",
    "Then keep the format and create a similar tweet with the 5 questions below so that it follows the tweet of the first 7 questions.\n",
    "{text2}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": [
    "messages =  [      \n",
    "{'role':'user', 'content':'Hello, can you translate \"hello\" to spanist'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can only translate between English and Vietnamese. I am not able to translate into Spanish.\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are the English translator. You only know and only have the ability to translate back and forth between English and Vietnamese. If asked to translate into another language, the answer will be no.'},    \n",
    "{'role':'user', 'content':'Hello, can you translate \"hello\" to spanist'}  ]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·∫øn l∆∞u c√°c prompts/response c·ªßa qu√° kh·ª©\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "name large price medium prices small price \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\n",
    "If food is not in menu, please suggest other food.\n",
    "If user ask about the price, please sum up the price of all items in the orders \n",
    "\"\"\"} ]  # accumulate messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  i want order\n",
      "BOT: Hi there! I'm here to help you with your order. What would you like to order?\n",
      "You:  2 cheese burger and 1 orange juice\n",
      "BOT: I'm sorry, but we don't have cheese burgers on our menu. Could I suggest something else? We have delicious pizzas, fries, and salads.\n",
      "You:  a pizza and salad\n",
      "BOT: Great choice! Which type of pizza would you like? We have pepperoni, cheese, and eggplant. And for the salad, would you like a Greek salad?\n",
      "You:  2 eggplant pizza and a greek salad\n",
      "BOT: Sounds delicious! Just to confirm, you'd like 2 eggplant pizzas and 1 Greek salad, right? Is there anything else you'd like to add to your order?\n",
      "You:  no, how much in total\n",
      "BOT: Alright! Let me calculate the total for you. \n",
      "\n",
      "2 eggplant pizzas at $11.95 each would be $23.90. \n",
      "1 Greek salad is $7.25. \n",
      "\n",
      "So the total for your order is $31.15. \n",
      "\n",
      "Is there anything else I can assist you with?\n",
      "You:  how much is a cheese burger?\n",
      "BOT: I apologize, but we don't have cheese burgers on our menu. Is there anything else I can help you with?\n",
      "Thanks!\n"
     ]
    }
   ],
   "source": [
    "exit_keyword = \"exit\"\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "     # exit case\n",
    "    if user_input == exit_keyword:\n",
    "        print(\"Thanks!\")\n",
    "        break\n",
    "    \n",
    "    print(\"You: \", user_input,  flush=True)\n",
    "    \n",
    "    # add prompts user to context\n",
    "    context.append({'role': 'user', 'content': f\"{user_input}\"})\n",
    "    \n",
    "    # get response\n",
    "    response = get_completion_from_messages(context)\n",
    "    \n",
    "    # display response\n",
    "    print(\"BOT:\", response,  flush=True)\n",
    "    \n",
    "    # add response to context\n",
    "    context.append({'role': 'assistant', 'content': f\"{response}\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
